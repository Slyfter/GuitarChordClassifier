{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This jupyter notebook was used to finetune the resnet model for guitar chords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to C:\\Users\\slyft/.cache\\torch\\hub\\checkpoints\\resnet152-f82ba261.pth\n",
      "100%|██████████| 230M/230M [00:21<00:00, 11.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet152(weights=\"ResNet152_Weights.DEFAULT\")\n",
    "\n",
    "num_classes = 14\n",
    "\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, num_classes)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.00175, momentum=0.9, weight_decay=0.01)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the training and testing directories\n",
    "train_dir = 'data/training'  # Path to the folder containing subfolders of training data\n",
    "test_dir = 'data/test'  # Path to the folder containing subfolders of testing data\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply the transformations when loading the datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "validation_dataset = ImageFolder(test_dir, transform=val_transform)\n",
    "\n",
    "batch_size = 64  # Define your preferred batch size\n",
    "\n",
    "# Create data loaders for the training and validation sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 2.6175\n",
      "Validation Loss: 2.5052, Validation Accuracy: 18.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Training Loss: 2.3381\n",
      "Validation Loss: 2.0930, Validation Accuracy: 30.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Training Loss: 1.8375\n",
      "Validation Loss: 1.5522, Validation Accuracy: 49.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Training Loss: 1.1876\n",
      "Validation Loss: 0.8188, Validation Accuracy: 75.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Training Loss: 0.6681\n",
      "Validation Loss: 0.5940, Validation Accuracy: 83.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Training Loss: 0.3883\n",
      "Validation Loss: 0.3052, Validation Accuracy: 92.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Training Loss: 0.2236\n",
      "Validation Loss: 0.1984, Validation Accuracy: 95.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Training Loss: 0.1351\n",
      "Validation Loss: 0.1447, Validation Accuracy: 95.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Training Loss: 0.1071\n",
      "Validation Loss: 0.1180, Validation Accuracy: 97.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Training Loss: 0.0952\n",
      "Validation Loss: 0.0761, Validation Accuracy: 98.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Training Loss: 0.0829\n",
      "Validation Loss: 0.0959, Validation Accuracy: 97.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Training Loss: 0.0764\n",
      "Validation Loss: 0.0961, Validation Accuracy: 97.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Training Loss: 0.0663\n",
      "Validation Loss: 0.0767, Validation Accuracy: 98.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Training Loss: 0.0567\n",
      "Validation Loss: 0.0871, Validation Accuracy: 97.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Training Loss: 0.0377\n",
      "Validation Loss: 0.0707, Validation Accuracy: 98.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Training Loss: 0.0330\n",
      "Validation Loss: 0.0606, Validation Accuracy: 97.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Training Loss: 0.0297\n",
      "Validation Loss: 0.0682, Validation Accuracy: 97.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Training Loss: 0.0250\n",
      "Validation Loss: 0.0717, Validation Accuracy: 97.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Training Loss: 0.0329\n",
      "Validation Loss: 0.0633, Validation Accuracy: 98.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Training Loss: 0.0215\n",
      "Validation Loss: 0.0762, Validation Accuracy: 97.37%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # Adjust the number of training epochs as needed\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0  # Initialize the running loss for the epoch\n",
    "\n",
    "    # Wrap the train_dataloader with tqdm for the loading bar\n",
    "    train_dataloader_with_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    \n",
    "    # Training phase\n",
    "    resnet.train()\n",
    "    for images, labels in train_dataloader_with_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()  # Accumulate the loss\n",
    "        \n",
    "        # Update the loading bar with the current loss value\n",
    "        train_dataloader_with_bar.set_postfix({'Loss': loss.item()})\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataloader)  # Calculate the average epoch loss\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    resnet.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = running_val_loss / len(validation_dataloader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model if validation loss decreased\n",
    "\n",
    "    model_folder = 'models'\n",
    "    if val_loss < best_val_loss:\n",
    "        # Create the model folder if it doesn't exist\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "        \n",
    "        # Define the file path within the model folder\n",
    "        model_path = os.path.join(model_folder, \"best_model.pth\")\n",
    "        \n",
    "        # Save the model to the specified file path\n",
    "        torch.save(resnet.state_dict(), model_path)\n",
    "        \n",
    "        best_val_loss = val_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Validation: \n",
    "\n",
    "The training loss decreases significantly over the epochs, from 2.6175 in the first epoch to 0.0215 in the last epoch, indicating that the network is learning effectively from the training data.\n",
    "\n",
    "The validation loss also decreases over the epochs, from 2.5052 in the first epoch to 0.0762 in the last epoch. However, the validation loss does not decrease as steadily as the training loss, and even increases in some epochs (for example, between the 10th and 11th epoch, and the 19th and 20th epoch). This could potentially suggest the model is starting to overfit to the training data, as its performance on unseen data (validation set) is getting worse while its performance on the training data continues to improve.\n",
    "\n",
    "The validation accuracy increases over the epochs, from 18.14% in the first epoch to 97.37% in the last epoch, indicating that the network's ability to correctly classify unseen images is improving. However, similar to the validation loss, the validation accuracy does not steadily increase, and decreases in some epochs, which could potentially suggest overfitting. Some techniques have been applied in the code above to counter overfitting:\n",
    "- Data augmentation\n",
    "- L2 Regularization\n",
    "- Saving model with lowest validation loss \n",
    "- Hyperparameter tuning - \n",
    "    this process undoubtedly required the most time. The fine-tuning of hyperparameters, such as the batch size, learning rate, and number of epochs involved incremental modifications and observing their respective impact on the model's performance.\n",
    "\n",
    "\n",
    "Overall, the network shows a decent performance with high accuracy on the validation set. An additional test with the 'unknown' dataset provides a more unbiased evaluation of the network's abilities (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 71.42857142857143%\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the fine-tuned model parameters\n",
    "state_dict = torch.load(\"models/best_model.pth\")\n",
    "\n",
    "# Load the state dict into the resnet model\n",
    "resnet.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# Define the path to the test directory\n",
    "unknown_dir = 'data/unknown'  # Replace with the path to your folder containing subfolders of test data\n",
    "\n",
    "# Define the transformations to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the test dataset and data loader\n",
    "unknown_dataset = ImageFolder(unknown_dir, transform=transform)\n",
    "unknown_dataloader = DataLoader(unknown_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Testing phase\n",
    "with torch.no_grad():\n",
    "    for images, labels in unknown_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test accuracy: {accuracy}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7701969d6674564bee76e3418402dccc7bfd84153a6cde981996f00dd9db6766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
